{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fc0887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T21:55:41.601142Z",
     "iopub.status.busy": "2025-11-10T21:55:41.600361Z",
     "iopub.status.idle": "2025-11-10T21:55:43.580874Z",
     "shell.execute_reply": "2025-11-10T21:55:43.580081Z"
    },
    "papermill": {
     "duration": 1.986813,
     "end_time": "2025-11-10T21:55:43.582586",
     "exception": false,
     "start_time": "2025-11-10T21:55:41.595773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bec7212",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-10T21:55:43.590561Z",
     "iopub.status.busy": "2025-11-10T21:55:43.589654Z",
     "iopub.status.idle": "2025-11-10T21:55:44.257424Z",
     "shell.execute_reply": "2025-11-10T21:55:44.256147Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.67315,
     "end_time": "2025-11-10T21:55:44.259186",
     "exception": false,
     "start_time": "2025-11-10T21:55:43.586036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file = \"/kaggle/input/fii-nn-2025-homework-3/extended_mnist_train.pkl\"\n",
    "test_file = \"/kaggle/input/fii-nn-2025-homework-3/extended_mnist_test.pkl\"\n",
    "\n",
    "with open(train_file, \"rb\") as fp:\n",
    "    train = pickle.load(fp)\n",
    "\n",
    "with open(test_file, \"rb\") as fp:\n",
    "    test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a673db",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-10T21:55:44.267812Z",
     "iopub.status.busy": "2025-11-10T21:55:44.266994Z",
     "iopub.status.idle": "2025-11-10T21:55:44.510755Z",
     "shell.execute_reply": "2025-11-10T21:55:44.508777Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.250676,
     "end_time": "2025-11-10T21:55:44.513297",
     "exception": false,
     "start_time": "2025-11-10T21:55:44.262621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for image, label in train:\n",
    "    train_data.append(image.flatten())\n",
    "    train_labels.append(label)\n",
    "\n",
    "train_data = np.array(train_data, dtype=np.float32)\n",
    "train_labels = np.array(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4781ca75",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-10T21:55:44.520237Z",
     "iopub.status.busy": "2025-11-10T21:55:44.519878Z",
     "iopub.status.idle": "2025-11-10T21:55:44.564829Z",
     "shell.execute_reply": "2025-11-10T21:55:44.563927Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.051054,
     "end_time": "2025-11-10T21:55:44.567315",
     "exception": false,
     "start_time": "2025-11-10T21:55:44.516261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for image, label in test:\n",
    "    test_data.append(image.flatten())\n",
    "\n",
    "test_data = np.array(test_data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4beda0d5",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-10T21:55:44.574476Z",
     "iopub.status.busy": "2025-11-10T21:55:44.574166Z",
     "iopub.status.idle": "2025-11-10T21:55:44.594365Z",
     "shell.execute_reply": "2025-11-10T21:55:44.593420Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.025512,
     "end_time": "2025-11-10T21:55:44.595882",
     "exception": false,
     "start_time": "2025-11-10T21:55:44.570370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, input_size=784, hidden_size=100, output_size=10, \n",
    "                 learning_rate=0.01, dropout_rate=0.0):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / hidden_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        \n",
    "        self.z1 = None\n",
    "        self.a1 = None\n",
    "        self.z2 = None\n",
    "        self.a2 = None\n",
    "        self.dropout_mask = None\n",
    "        \n",
    "    def relu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def relu_derivative(self, z):\n",
    "        return (z > 0).astype(float)\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "    \n",
    "    def forward(self, X, training=True):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        \n",
    "        if training and self.dropout_rate > 0:\n",
    "            self.dropout_mask = (np.random.rand(*self.a1.shape) > self.dropout_rate).astype(float)\n",
    "            self.a1 *= self.dropout_mask\n",
    "            self.a1 /= (1 - self.dropout_rate)\n",
    "        \n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        \n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, output):\n",
    "        batch_size = X.shape[0]\n",
    "        \n",
    "        dz2 = output - y\n",
    "        dW2 = np.dot(self.a1.T, dz2) / batch_size\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / batch_size\n",
    "        \n",
    "        da1 = np.dot(dz2, self.W2.T)\n",
    "        \n",
    "        if self.dropout_rate > 0 and self.dropout_mask is not None:\n",
    "            da1 *= self.dropout_mask\n",
    "            da1 /= (1 - self.dropout_rate)\n",
    "        \n",
    "        dz1 = da1 * self.relu_derivative(self.z1)\n",
    "        dW1 = np.dot(X.T, dz1) / batch_size\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / batch_size\n",
    "        \n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        batch_size = y_true.shape[0]\n",
    "        log_likelihood = -np.log(y_pred[np.arange(batch_size), np.argmax(y_true, axis=1)] + 1e-7)\n",
    "        loss = np.mean(log_likelihood)\n",
    "        return loss\n",
    "    \n",
    "    def compute_accuracy(self, y_true, y_pred):\n",
    "        predictions = np.argmax(y_pred, axis=1)\n",
    "        true_labels = np.argmax(y_true, axis=1)\n",
    "        return np.mean(predictions == true_labels)\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, \n",
    "            epochs=50, batch_size=128, verbose=True):\n",
    "        n_samples = X_train.shape[0]\n",
    "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            indices = np.random.permutation(n_samples)\n",
    "            X_shuffled = X_train[indices]\n",
    "            y_shuffled = y_train[indices]\n",
    "            \n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                X_batch = X_shuffled[i:i+batch_size]\n",
    "                y_batch = y_shuffled[i:i+batch_size]\n",
    "                \n",
    "                output = self.forward(X_batch, training=True)\n",
    "                self.backward(X_batch, y_batch, output)\n",
    "            \n",
    "            train_output = self.forward(X_train, training=False)\n",
    "            train_loss = self.compute_loss(y_train, train_output)\n",
    "            train_acc = self.compute_accuracy(y_train, train_output)\n",
    "            \n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            \n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_output = self.forward(X_val, training=False)\n",
    "                val_loss = self.compute_loss(y_val, val_output)\n",
    "                val_acc = self.compute_accuracy(y_val, val_output)\n",
    "                history['val_loss'].append(val_loss)\n",
    "                history['val_acc'].append(val_acc)\n",
    "                \n",
    "                if verbose and (epoch + 1) % 10 == 0:\n",
    "                    print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                          f\"Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, \"\n",
    "                          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            else:\n",
    "                if verbose and (epoch + 1) % 10 == 0:\n",
    "                    print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                          f\"Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X, training=False)\n",
    "        return np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1b94f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T21:55:44.602969Z",
     "iopub.status.busy": "2025-11-10T21:55:44.602656Z",
     "iopub.status.idle": "2025-11-10T21:55:45.043563Z",
     "shell.execute_reply": "2025-11-10T21:55:45.042588Z"
    },
    "papermill": {
     "duration": 0.446302,
     "end_time": "2025-11-10T21:55:45.045158",
     "exception": false,
     "start_time": "2025-11-10T21:55:44.598856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 54000\n",
      "Validation samples: 6000\n",
      "Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "mean = train_data.mean()\n",
    "std = train_data.std() + 1e-7\n",
    "train_data = (train_data - mean) / std\n",
    "test_data = (test_data - mean) / std\n",
    "\n",
    "train_labels_onehot = np.eye(10)[train_labels]\n",
    "\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(train_data))\n",
    "split_idx = int(0.9 * len(train_data))\n",
    "train_idx = indices[:split_idx]\n",
    "val_idx = indices[split_idx:]\n",
    "\n",
    "X_train = train_data[train_idx]\n",
    "y_train = train_labels_onehot[train_idx]\n",
    "X_val = train_data[val_idx]\n",
    "y_val = train_labels_onehot[val_idx]\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Validation samples: {X_val.shape[0]}\")\n",
    "print(f\"Test samples: {test_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dfb73e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T21:55:45.052364Z",
     "iopub.status.busy": "2025-11-10T21:55:45.052028Z",
     "iopub.status.idle": "2025-11-10T21:58:54.943641Z",
     "shell.execute_reply": "2025-11-10T21:58:54.942736Z"
    },
    "papermill": {
     "duration": 189.900149,
     "end_time": "2025-11-10T21:58:54.948372",
     "exception": false,
     "start_time": "2025-11-10T21:55:45.048223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP with Backpropagation + DROPOUT regularization\n",
      "Epoch 10/150 - Loss: 0.0532, Acc: 0.9841, Val Loss: 0.0904, Val Acc: 0.9717\n",
      "Epoch 20/150 - Loss: 0.0303, Acc: 0.9913, Val Loss: 0.0824, Val Acc: 0.9762\n",
      "Epoch 30/150 - Loss: 0.0193, Acc: 0.9950, Val Loss: 0.0846, Val Acc: 0.9773\n",
      "Epoch 40/150 - Loss: 0.0129, Acc: 0.9970, Val Loss: 0.0854, Val Acc: 0.9773\n",
      "Epoch 50/150 - Loss: 0.0100, Acc: 0.9977, Val Loss: 0.0884, Val Acc: 0.9778\n",
      "Epoch 60/150 - Loss: 0.0075, Acc: 0.9988, Val Loss: 0.0895, Val Acc: 0.9780\n",
      "Epoch 70/150 - Loss: 0.0063, Acc: 0.9990, Val Loss: 0.0897, Val Acc: 0.9778\n",
      "Epoch 80/150 - Loss: 0.0057, Acc: 0.9990, Val Loss: 0.0935, Val Acc: 0.9777\n",
      "Epoch 90/150 - Loss: 0.0044, Acc: 0.9994, Val Loss: 0.0934, Val Acc: 0.9785\n",
      "Epoch 100/150 - Loss: 0.0034, Acc: 0.9994, Val Loss: 0.1008, Val Acc: 0.9777\n",
      "Epoch 110/150 - Loss: 0.0036, Acc: 0.9995, Val Loss: 0.1058, Val Acc: 0.9768\n",
      "Epoch 120/150 - Loss: 0.0027, Acc: 0.9998, Val Loss: 0.1014, Val Acc: 0.9780\n",
      "Epoch 130/150 - Loss: 0.0024, Acc: 0.9998, Val Loss: 0.1037, Val Acc: 0.9778\n",
      "Epoch 140/150 - Loss: 0.0021, Acc: 0.9998, Val Loss: 0.1070, Val Acc: 0.9775\n",
      "Epoch 150/150 - Loss: 0.0018, Acc: 0.9999, Val Loss: 0.1074, Val Acc: 0.9782\n",
      "\n",
      "Final Training Accuracy: 0.9999\n",
      "\n",
      "Final Validation Accuracy: 0.9782\n",
      "\n",
      "Regularization technique: DROPOUT (rate=0.4)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "mlp = MLP(\n",
    "    input_size=784,\n",
    "    hidden_size=100,\n",
    "    output_size=10,\n",
    "    learning_rate=0.1,\n",
    "    dropout_rate=0.3\n",
    ")\n",
    "\n",
    "print(\"\\nTraining MLP with Backpropagation + DROPOUT regularization\")\n",
    "\n",
    "history = mlp.fit(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    epochs=150,\n",
    "    batch_size=128,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Training Accuracy: {history['train_acc'][-1]:.4f}\")\n",
    "print(f\"\\nFinal Validation Accuracy: {history['val_acc'][-1]:.4f}\")\n",
    "print(\"\\nRegularization technique: DROPOUT (rate=0.4)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f4467d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-10T21:58:54.956872Z",
     "iopub.status.busy": "2025-11-10T21:58:54.956555Z",
     "iopub.status.idle": "2025-11-10T21:58:55.033732Z",
     "shell.execute_reply": "2025-11-10T21:58:55.032953Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.083349,
     "end_time": "2025-11-10T21:58:55.035399",
     "exception": false,
     "start_time": "2025-11-10T21:58:54.952050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = mlp.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b69466",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-10T21:58:55.044731Z",
     "iopub.status.busy": "2025-11-10T21:58:55.043962Z",
     "iopub.status.idle": "2025-11-10T21:58:55.100803Z",
     "shell.execute_reply": "2025-11-10T21:58:55.100076Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.063114,
     "end_time": "2025-11-10T21:58:55.102513",
     "exception": false,
     "start_time": "2025-11-10T21:58:55.039399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is how you prepare a submission for the competition\n",
    "predictions_csv = {\n",
    "    \"ID\": [],\n",
    "    \"target\": [],\n",
    "}\n",
    "\n",
    "for i, label in enumerate(predictions):\n",
    "    predictions_csv[\"ID\"].append(i)\n",
    "    predictions_csv[\"target\"].append(label)\n",
    "\n",
    "df = pd.DataFrame(predictions_csv)\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13980102,
     "sourceId": 117046,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 199.8183,
   "end_time": "2025-11-10T21:58:55.626751",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-10T21:55:35.808451",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
